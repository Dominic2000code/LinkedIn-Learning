{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07a9e722",
   "metadata": {},
   "source": [
    "# Building and Deploying Deep Learning Applications in TensorFlow\n",
    "\n",
    "**Instructor:** Adam Geitgey\n",
    "\n",
    "TensorFlow is one of the most popular deep learning frameworks available. It's used for everything from cutting-edge machine learning research to building new features for the hottest start-ups in Silicon Valley. In this course, learn how to install TensorFlow and use it to build a simple deep learning model. After he shows how to get TensorFlow up and running, instructor Adam Geitgey demonstrates how to create and train a machine learning model, as well as how to leverage visualization tools to analyze and improve your model. Finally, he explains how to deploy models locally or in the cloud. When you wrap up this course, you'll be ready to start building and deploying your own models with TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f0e867",
   "metadata": {},
   "source": [
    "* **TensorFlow** is a software framework for building and deploying machine learning models\n",
    "* **Machine learning:** computer algorithms that have the ability to learn without explicitly being programmed.\n",
    "    * With traditional programming, we write the program that tells the computer exactly what to do to complete the task \n",
    "    * WIth ML, we don't explicitly tell the computer how to do something, but instead we show it training data and the ML algorithm uses the training data to come up with its own rules to complete the task\n",
    "    \n",
    "#### TensorFlow\n",
    "* Developed internally at Google\n",
    "* Designed to be a common platform fr=or building ML applications internally\n",
    "* Made public in late 2015\n",
    "* First stable version in 2017 and open sourced (licensed under Apache software license)\n",
    "    * This means you can use it, modify it, and even redistribute a modified version of it without having to pay any licensing fees to use TF\n",
    "* TensorFlow gives you the basic building blocks that you need to design, train, and deploy machine learning models' it's flexible enough to be used for several different types of ML types of algorithms, but is typically used to build DNNs\n",
    "* DNNs built with TF are used in many different areas like:\n",
    "    * Image recognition\n",
    "    * Speech recognition\n",
    "    * Image style transfer\n",
    "    * Language translation\n",
    "* As it was creted by Google, it works well with many Google products (like their Cloud ML platform) and for deploying ML models on Android mobile phones\n",
    "* TensorFlow is a low level toolkit and it can take quite a few lines of code to build an ML model in TF\n",
    "    * Because of this, there are wrappers for TensorFlow that simplify common operations \n",
    "    * The most popular wrapper for TensorFlow is **Keras**\n",
    "    * **Keras** is a high-level programming toolkit that makes it easy to build many different types of neural networks with only a few lines of code\n",
    "    * This is a great choice if you don't need the low level flexibility of TF\n",
    "    * It is recommendable to learn how to use TF on its own first, to make sure you understand what's going on behind the scenes and once you're familiar with TensorFlow, it's great to also learn how to use Keras (which can be a great time-saver)\n",
    " \n",
    "#### TensorFlow alternatives\n",
    "* theano : [see here](http://deeplearning.net/software/theano/)\n",
    "* torch : [see here](http://torch.ch/)\n",
    "* Pytorch : [see here](http://pytorch.org/)\n",
    "\n",
    "#### Why is it called Tensorflow?\n",
    "* The name TensorFlow comes from the design of the system\n",
    "* TensorFlow is designed to work with large data sets made of many different individual attributes\n",
    "* Any data that you want to process with TensorFlow has to be stored in the multi-dimensional array.\n",
    "* These multi-dimensional arrays are also called **tensors**.\n",
    "* To run operations on the data set, we construct a computational graph similar to a flow chart that determines how data flows from one operation to the next: for this reason it is called **TensorFlow**\n",
    "\n",
    "<img src='data/tensor1.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* It's called **TensorFlow** because you're defining how data or tensors will *flow* through the system\n",
    "\n",
    "<img src='data/tensor2.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* TensorFlow is designed to be very generic and open-ended.\n",
    "* It can be used to model almost any series of calculations\n",
    "* It typically is used to build DNNs, but can be used to build almost any model\n",
    "\n",
    "#### Pros\n",
    "* Powerful and flexible\n",
    "* Can build almost anything\n",
    "\n",
    "#### Cons\n",
    "* High-learning cuve\n",
    "* Little done for you\n",
    "\n",
    "#### Hardware, software, and language requirements\n",
    "* TensorFlow has different hardware and software requirements for the development phase and the runtime phase\n",
    "    * **Development phase:**\n",
    "        * When you are coding and training an NN\n",
    "        * This is usually done on your own computer\n",
    "    * **Runtime (or inference) phase:**\n",
    "        * When you are making predictions with a trained NN\n",
    "        * This may be done on your own computer, on a cloud server, or on a user's computer or mobile device\n",
    "        \n",
    "#### Development phase requirements\n",
    "* Windows, macOS, or Linux\n",
    "* Can use multiple Linux computers (locally or in the cloud) for very large projects\n",
    "\n",
    "#### Runtime phase supports\n",
    "* Computers running Windows, macOS, or Linux\n",
    "* Linux servers running TensorFlow Serving\n",
    "* Google's Cloud Machine Learning Engine service\n",
    "* iOS or Android mobile apps\n",
    "\n",
    "\n",
    "* **The flexibility to run the same machine learning model on many different platforms is one of the best features of TensorFlow**\n",
    "\n",
    "#### GPU Acceleration\n",
    "* TensorFlow can take advantage of video cards with GPUs, like NVIDIA-brand GPUs (graphic processing units) to speed up training\n",
    "* GPUs are chips originally to speed up 3D video games but they are also good at the algebraic calculations needed to train neural networks\n",
    "* GPUs can greatly decrease NN training times for large neural networks\n",
    "* In fact, deep learning is only possible because GPUs let us train large neural networks in a reasonable amount of time \n",
    "* Keep in mind that TensorFlow **only supports NVIDIA-brand GPUs**.\n",
    "* We won't be using a GPU in this course, but keep in mind that having one is helpful when working on large projects.\n",
    "* **Note** that using a GPU with TensorFlow requires installing additional software from NVIDIA (**CUDA** and **cuDNN**) that aren't open source\n",
    "\n",
    "#### Programming Language Support\n",
    "* TensorFlow's core execution engine is written in C++ for speed\n",
    "* TensorFlow also lets other progamming languages control the C++ core\n",
    "* Python is the best supported and easiest language to use with TensorFlow\n",
    "* The main downside of using Python is that it is relatively slow to execute compared to a low-level language like the C or C++."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a8f72d",
   "metadata": {},
   "source": [
    "### The train/test/evaluation flow in TensorFlow\n",
    "\n",
    "#### Supervised Learning workflow:\n",
    "* Step 1: Choose a model\n",
    "* Step 2: Training phase\n",
    "* Step 3: Testing phase\n",
    "* Step 4: Evaluation phase\n",
    "\n",
    "#### TensorFlow workflow:\n",
    "* In TensorFlow, we'll follow these same steps\n",
    "* **However, you have to implement it yourself and set up a lot of the mechanics.**\n",
    "\n",
    "\n",
    "#### Step 1: Build a Model (as a Graph)\n",
    "* First define each layer of the NN and connect them together so that data flows from the first layer through to the last layer.\n",
    "* Then add the placeholder node that represents the data that will be fed in as input to the neural network\n",
    "* Add another placeholder node that represents the output, or values predicted by the neural network. \n",
    "* Next, we need a way to measure the accuracy of the neural network's predictions\n",
    "* We'll define the function that measures the accuracy of each prediction during the training process (this is the **loss function**).\n",
    "* The loss function gets added to the graph as its own operation \n",
    "* Then we have to create the **optimizer function** that tells TensorFlow how we want to train the model. When we run this function it will perform one training step on our model. We call this node the \"training operation\" in the chart below.\n",
    "* The training operation will train the neural network by looking at the results of the loss function and using that to adjust the weights of each layer in the neural network until they produce the desired output.\n",
    "* **Because this is a computational graph, there's no single start or end.** We can start processing at any node in the graph.\n",
    "* When you run an operation, TensorFlow will push any needed data through the network according to the pathways you defined to make everything work. \n",
    "* Once the ML algorithm is fully defined as a computational graph, we can move on to the training phase.\n",
    "\n",
    "<img src='data/tensor3.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "#### Step 2: Training Phase\n",
    "* **Before we can perform any operations, we have to create a TensorFlow *session*.**\n",
    "* A **session is an object in TensorFlow that runs operations on the graph and tracks the state of each node in the graph.**\n",
    "* Once the session object is created, we can ask it to run any operation in the graph.\n",
    "* To train the model, we'll call the training operation over and over.\n",
    "* Each time the training operation runs, we'll pass in new training data that will be used for that training pass\n",
    "* Then we'll check the current accuracy by call the loss function\n",
    "\n",
    "<img src='data/tensor4.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "#### TensorBoard\n",
    "* While the training process is running, we can watch the results graphically using a separate tool called **TensorBoard**. \n",
    "* TensorBoard is a web-based application that lets us visually monitor the system in real time.\n",
    "* We can use the graphs in TensorBoard to monitor how the accuracy is improving as the training process continues to run.\n",
    "\n",
    "<img src='data/tensor5.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "#### Step 3: Testing Phase\n",
    "* Now that the model is trained, we can move on to the testing phase.\n",
    "* We pass in testing data, and then measure the accuracy by calling the loss function.\n",
    "* The data will flow through the neural network and into the loss function, which will tell us how close the values predicted by the neural network were to the resl testing data.\n",
    "* Once we are happy with the accuracy of the predictions, we can save this model to a file \n",
    "* **When we save a trained model, we're actually writing out a copy of this graph, and a state of all nodes in the graph.**\n",
    "* When we load the model later, we're just restoring the graph to its previous state.\n",
    "\n",
    "<img src='data/tensor6.png' width=\"600\" height=\"300\" align=\"center\"/> \n",
    "\n",
    "#### Step 4: Evaluation phase\n",
    "* To use the model to make new predictions, we'll feed in data to the input node and call the output operation.\n",
    "* The data will flow through the neural network to the output node \n",
    "* The different nodes in the computational graph are used for different phases of the train/test evaluation flow.\n",
    "* In fact, when we are in the evaluation phase, and only using the graph to make new predictions, the loss function and the training operation are no longer needed at all \n",
    "* To make predictions, all we need are the nodes that make up the neural network itself. So when we deploy a trained neural network to the cloud or to a mobile device, we can strip out all the other parts of the computational graph and only include the parts we need to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02ab7c7",
   "metadata": {},
   "source": [
    "### Build a simple model in TensorFlow\n",
    "* Let's start with a very simple TensorFlow computational graph that adds two numbers, $X$ and $Y$, together. \n",
    "* This graph has two inputs, $X$ and $Y$, as well as one operation, called $addition$.\n",
    "* Here's what the computational graph would look like:\n",
    "\n",
    "<img src='data/tensor7.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* **Note that it's standard practice to `import tensorflow as tf`**\n",
    "* By default, TF outputs a lot of log messages to your console when you run the program. The messages can sometimes be helpful, but can also make the output difficult to read.\n",
    "* When you create a node in TF, you have to choose what kind of node to create.\n",
    "* The $X$ and $Y$ nodes (from the graph above) will be placeholder nodes that get assigned a new value each time we make a calculation, so we create them as placeholder nodes.\n",
    "* Then we pass the $X$ and $Y$ nodes into the addition node.\n",
    "* **Recall that a TensorFlow session is an object that runs operations on the computation graph and tracks the state of each node in the graph.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37843294",
   "metadata": {},
   "source": [
    "### Options for Loading Data\n",
    "* TF supports different ways of loading datasets, depending on how much data you are dealing with (the more data you have, the more complicated it gets):\n",
    "    * **Preload data into memory**\n",
    "        * Simplest method\n",
    "        * Pass data to TF as a single array\n",
    "        * Just write plain Python code to load data (nothing TF-specific)\n",
    "    * **Feed data step-by-step**\n",
    "        * Slightly more complicated version\n",
    "        * Feeds data step-by-step to TF as TF requests it\n",
    "        * Gives you more control over when the data is loaded\n",
    "        * Requires that you manage everything yourself\n",
    "    * **Set up a custom data pipeline**\n",
    "        * This is the best option when you are working with enormous datasets like millions of images\n",
    "        * Allows TF to manage loading data into memory itself as it needs it\n",
    "        \n",
    "#### Preload Data into Memory\n",
    "* Quick and easy\n",
    "* Works as long as the entire dataset fits into RAM\n",
    "* Use normal code with nothing TF-specific \n",
    "* Can use helpful Python data libraries like pandas\n",
    "\n",
    "#### Feed Data Step-by-Step\n",
    "* TF calles you custom data loader function each time it needs more data\n",
    "* This makes it possible to wor with larger datasets\n",
    "* But you have to write all the data loading code yourself\n",
    "* Normal Python code is used\n",
    "\n",
    "#### Set Up a Data Pipeline\n",
    "* Scales to infinitely large datasets\n",
    "* TF provides a good bit of plumbing for setting up a data pipeline, but you still have to write a good bit of code yourself\n",
    "* Requires writing TensorFlow-specific code (usually can't take advantage of other Python data processing libraries)\n",
    "* **Supports parallel processing** across multiple CPUs\n",
    "* This means that the training process doesn't have to stop and wait while the next chunk of data is loaded for the next training pass.\n",
    "\n",
    "#### Data Pipeline Example\n",
    "* Say our dataset is made up of hundreds of separate CSV files\n",
    "* First step: create a list of all the file names of the data files that need to be processed\n",
    "* Shuffle file names into a random order\n",
    "* Add the shuffled file names into a file processing queue\n",
    "* Next, individual file names will be pulled out of the file processing queue and sent to the CSV file reader\n",
    "* The CSV reader will parse the raw data out of the CSV file and break it up into individual records.\n",
    "* Each record in the CSV file is fed into the record decoder\n",
    "* The record decoder pulls out and formats the individual values from each record\n",
    "* Finally, queue up each record in the data queue, where it's ready to be fed into your neural network for training\n",
    "    * TF provides functions and helpers to help you build each step of this pipeline, and once you've built the pipeline, TF will execute it for you. \n",
    "    * Especially common for image-based datasets\n",
    "    \n",
    "#### Recommendations\n",
    "* Use the simplest solution (preloading) if possible\n",
    "* Build a data pipeline if your dataset becomes too large\n",
    "* Only add more complexity when you need it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78561d70",
   "metadata": {},
   "source": [
    "### Load the data set\n",
    "* We need to scale our data to be between 0 and 1\n",
    "* For this we can use the `MinMaxScaler()`\n",
    "    * pass in parameter `feature_range` and set to `=(0,1)`\n",
    "* First, create the scalers, then scale the training inputs and outputs:\n",
    "\n",
    "```\n",
    "X_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "Y_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "# Scale training inputs and outputs\n",
    "X_scaled_training = X_scaler.fit_transform(X_training)\n",
    "Y_scaled_training = Y_scaler.fit_transform(Y_training)\n",
    "\n",
    "# Scale testing inputs and outputs\n",
    "X_scaled_testing = X_scaler.transform(X_test)\n",
    "Y_scaled_testing =  Y_scaler.transform(Y_test)\n",
    "```\n",
    "* **Recall that the scaler transforms the data by multiplying the data by a constant value and then adding a constant value.**\n",
    "* We can get these values with:\n",
    "    * **`X_scaler.scale_[0]`**\n",
    "    * **`Y_scaler.scale_[0]`**\n",
    "* **This will be useful to know later, when we want to make predictions with the neural network and be able to unscale the data back to the original units.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9f817f",
   "metadata": {},
   "source": [
    "### Define the model structure\n",
    "* To keep things organized, it's helpful to **put each layer of our neural network in its own variable scope.**\n",
    "* Normally in Python, we organize our code by creating new functions. In TensorFlow we can create variable scopes by using the **`tf.variablescope`** function instead.\n",
    "    * Any variables we create within this scope will automatically get a prefix of input to their name internally in TensorFlow.\n",
    "    * TensorFlow has the ability to generate diagrams of the computational graph.\n",
    "    * By putting our nodes into scopes, it helps TF genearte more useful diagrams that are easier to understand.\n",
    "    * **Everything within the same scope will be grouped together within the diagram.**\n",
    "    \n",
    "* Note that when we create a new node, we need to it what type of tensor to accept\n",
    "* We also need to tell it the size or shape of the tensor to expect\n",
    "    * For our case we use `shape = None, number_of_inputs`\n",
    "* We also need to set the **variable initializer**.\n",
    "    * With neural networks, a lot of research has gone into the best initial values to use for weights\n",
    "    * **A good choice is an algorithm called Xavier initialization.**\n",
    "    * TF has a built in `xavier_initizer` function:\n",
    "    * `initializer = tf.contrib.layers.xaver_initializer`\n",
    "* The last step of defining this layer is multiplying the weights by the inputs and calling an activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c27090c",
   "metadata": {},
   "source": [
    "<img src='data/tensor8.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "<img src='data/tensor9.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48eb45ec",
   "metadata": {},
   "source": [
    "### Log\n",
    "* In TF, it can be difficult to visualize exactly what's happening during the training process\n",
    "* Luckily, TF provides **TensorBoard**, a web-based interface that lets us visualize and monitor our ML model.\n",
    "* One of the most useful features of TensorBoard is that it lets us track the accuracy of our model as it trains\n",
    "\n",
    "#### Scalars\n",
    "* The first tab of TensorBoard is called **`Scalars`**\n",
    "* The term scalar here just means a single value, as opposed to an array of multiple numbers.\n",
    "* This is the section of TensorBoard where you can log single values over time and view the results as graphs\n",
    "* Being able to visualize your data is very helpful, however you have to tell TensorFlow to log the values you want to visualize (it won't automatically create charts like this for you).\n",
    "* **model checkpoint file** is a file that contains the state of a trained ML model\n",
    "\n",
    "## TensorBoard\n",
    "\n",
    "### Visualize the computational graph\n",
    "* TensorBoard takes what we do in TF and creates a graphical representation of it \n",
    "    * Before we can open up TensorBoard, we need some log files to look at\n",
    "* To see our computational graph, click on the graphs tab at the top; this is a visual representation of our computational graph\n",
    "* Each variable scope or operation in our neural network is represented by a box in this diagram \n",
    "\n",
    "<img src='data/tensor10.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* Each line represents a tensor or array of data being passed between the nodes.\n",
    "* The **first number represents the batch size** (in the diagram below, the **`?`**)\n",
    "* The batch size can very each time, and for this reason this nummber is represented by a question mark **unless specifically defined**.\n",
    "\n",
    "<img src='data/tensor11.png' width=\"300\" height=\"150\" align=\"center\"/>\n",
    "\n",
    "* We can also zoom in to each node and see more detail \n",
    "* Below, we expand the input node by clicking on the plus sign in the top right corner.\n",
    "* You can see that inside the input later is the placeholder value we pass in \n",
    "\n",
    "<img src='data/tensor12.png' width=\"300\" height=\"150\" align=\"center\"/>\n",
    "\n",
    "* Below, we expand a node that is slightly more complicated than the input node (layer 1)\n",
    "* This shows us exactly what is happening inside a layer of the neural network\n",
    "* The input values are fed in and then their matrix multiplied by the weights, then the bias is added, and then a ReLU (rectified linear unit) activation function is applied, and the result is sent to the next layer\n",
    "\n",
    "<img src='data/tensor14.png' width=\"400\" height=\"200\" align=\"center\"/>\n",
    "\n",
    "* Finally, we take a look at the cost node\n",
    "* We can see that the output of the neural network feeds into the cost function, where the current cost of the neural network is calculated\n",
    "* We can also see here that the value is saved as a metric clled current cost.\n",
    "    * If we look at the `scalars` tab, we'll be able to see the graph for this metric\n",
    "\n",
    "<img src='data/tensor15.png' width=\"400\" height=\"200\" align=\"center\"/>\n",
    "\n",
    "* Another great feature of TensorBoard is the ability to trace the path of data through the graph\n",
    "* The **`Trace Input`** slider highlights exactly the path data flows through to generate the output of the NN\n",
    "* **This is a very helpful way to debug a graph if things aren't working as expected.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bf0001",
   "metadata": {},
   "source": [
    "### Visualizing training runs\n",
    "* click on `logging` to see our charts\n",
    "* These graphs update automatically every minute that you train\n",
    "* If you want, you can kick off additional training runs\n",
    "* **Once you find the settings that work best, you might want to export this data to another program to create a report. to do that, click the show download data links button towards the top left.**\n",
    "\n",
    "<img src='data/tensor16.png' width=\"900\" height=\"450\" align=\"center\"/>\n",
    "\n",
    "* This will enable a new selection box in the bottom right\n",
    "* You can choose a single run and then you can export it as a csv or a json file\n",
    "* That file will have each point in the chart in the format you can easily open in the spreadsheet\n",
    "\n",
    "<img src='data/tensor17.png' width=\"300\" height=\"150\" align=\"center\"/>\n",
    "\n",
    "<img src='data/tensor18.png' width=\"300\" height=\"150\" align=\"center\"/>\n",
    "\n",
    "* When you're done, you can close TensorBoard by going back to the terminal window and hitting `CTRL + C`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913aa536",
   "metadata": {},
   "source": [
    "### Add custom visualizations to TensorBoard\n",
    "* TensorBoard allows you to create custom visualizations beyond just line graphs.\n",
    "* You can use these visualizations to monitor your machine learning model and what kind of data it's generating\n",
    "* Currently TF supports these types of visualizations\n",
    "\n",
    "#### Images\n",
    "* You create an image visualization by adding a **`tf.summary.image`** object to your graph and passing it the array you want to visualize\n",
    "* **This is helpful when you're building a neural network that classifies or generates images**\n",
    "\n",
    "<img src='data/tensor19.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "#### Audio\n",
    "* You can also listen to audio data in TensorBoard\n",
    "* **To add an audio player to TensorBoard, you create a new `tf.summary.audio` object and you add it to your computational graph.**\n",
    "* This is typically used when building models that recognize speech or generate sounds \n",
    "* It lets you hear the sound files that your model is processing \n",
    "\n",
    "<img src='data/tensor20.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "#### Histograms\n",
    "* You can also create interactive histograms and distribution graphs in TensorBoard\n",
    "* When you add a **`tf.summary.histogram()`** object to your computational graph, it creates both a histogram and a distribution graph\n",
    "\n",
    "<img src='data/tensor21.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* This chat shows us the range of predictions our neural network made at each step during training\n",
    "* We can see that with time, it learned to make predictions with a wider range of values\n",
    "\n",
    "<img src='data/tensor22.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* TensorBoard also lets us visualize histograms as a distribution chart\n",
    "* For this, click on `Distributions` and then expand the logging tab\n",
    "* These graphs show the same data as a 2D chart over time\n",
    "\n",
    "<img src='data/tensor23.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* **When you're building your own ML models, it's a great idea to add visualizations of any inputs and outputs you want to model**\n",
    "* **Doing that will make it a lot easier to understand what your model is actually doing.**\n",
    "* Once again, when you're done with TensorBoard, you can close it by going back to the terminal and hitting `CTRL + C`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817f941f",
   "metadata": {},
   "source": [
    "## Using a Trained TensorFlow\n",
    "\n",
    "### Export models for use in production\n",
    "* One of the best features of TF is that **we can take a model we've built and export it to a file and then run that file on Google's cloud servers.**\n",
    "* That let's us scale up any ML feature we build to an almost infinite scale without having to maintain our own servers.\n",
    "* But in order to do that, we have to tell Google how we want to run our model in producetion\n",
    "* **If we export this model to a file using the normal way of saving model checkpoint files, Google won't know which function we want to run. Instead, we need to export this model a special way where we define exactly what the start and end point of the model is that we want to run.**\n",
    "* The advantage of hosting your model in the cloud is that it is accessible from anywhere in the world. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
