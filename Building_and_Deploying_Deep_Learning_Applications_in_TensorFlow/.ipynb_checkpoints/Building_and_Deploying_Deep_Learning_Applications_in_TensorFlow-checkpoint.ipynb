{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "764c03db",
   "metadata": {},
   "source": [
    "# Building and Deploying Deep Learning Applications in TensorFlow\n",
    "\n",
    "**Instructor:** Adam Geitgey\n",
    "\n",
    "TensorFlow is one of the most popular deep learning frameworks available. It's used for everything from cutting-edge machine learning research to building new features for the hottest start-ups in Silicon Valley. In this course, learn how to install TensorFlow and use it to build a simple deep learning model. After he shows how to get TensorFlow up and running, instructor Adam Geitgey demonstrates how to create and train a machine learning model, as well as how to leverage visualization tools to analyze and improve your model. Finally, he explains how to deploy models locally or in the cloud. When you wrap up this course, you'll be ready to start building and deploying your own models with TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f289e7",
   "metadata": {},
   "source": [
    "* **TensorFlow** is a software framework for building and deploying machine learning models\n",
    "* **Machine learning:** computer algorithms that have the ability to learn without explicitly being programmed.\n",
    "    * With traditional programming, we write the program that tells the computer exactly what to do to complete the task \n",
    "    * WIth ML, we don't explicitly tell the computer how to do something, but instead we show it training data and the ML algorithm uses the training data to come up with its own rules to complete the task\n",
    "    \n",
    "#### TensorFlow\n",
    "* Developed internally at Google\n",
    "* Designed to be a common platform fr=or building ML applications internally\n",
    "* Made public in late 2015\n",
    "* First stable version in 2017 and open sourced (licensed under Apache software license)\n",
    "    * This means you can use it, modify it, and even redistribute a modified version of it without having to pay any licensing fees to use TF\n",
    "* TensorFlow gives you the basic building blocks that you need to design, train, and deploy machine learning models' it's flexible enough to be used for several different types of ML types of algorithms, but is typically used to build DNNs\n",
    "* DNNs built with TF are used in many different areas like:\n",
    "    * Image recognition\n",
    "    * Speech recognition\n",
    "    * Image style transfer\n",
    "    * Language translation\n",
    "* As it was creted by Google, it works well with many Google products (like their Cloud ML platform) and for deploying ML models on Android mobile phones\n",
    "* TensorFlow is a low level toolkit and it can take quite a few lines of code to build an ML model in TF\n",
    "    * Because of this, there are wrappers for TensorFlow that simplify common operations \n",
    "    * The most popular wrapper for TensorFlow is **Keras**\n",
    "    * **Keras** is a high-level programming toolkit that makes it easy to build many different types of neural networks with only a few lines of code\n",
    "    * This is a great choice if you don't need the low level flexibility of TF\n",
    "    * It is recommendable to learn how to use TF on its own first, to make sure you understand what's going on behind the scenes and once you're familiar with TensorFlow, it's great to also learn how to use Keras (which can be a great time-saver)\n",
    " \n",
    "#### TensorFlow alternatives\n",
    "* theano : [see here](http://deeplearning.net/software/theano/)\n",
    "* torch : [see here](http://torch.ch/)\n",
    "* Pytorch : [see here](http://pytorch.org/)\n",
    "\n",
    "#### Why is it called Tensorflow?\n",
    "* The name TensorFlow comes from the design of the system\n",
    "* TensorFlow is designed to work with large data sets made of many different individual attributes\n",
    "* Any data that you want to process with TensorFlow has to be stored in the multi-dimensional array.\n",
    "* These multi-dimensional arrays are also called **tensors**.\n",
    "* To run operations on the data set, we construct a computational graph similar to a flow chart that determines how data flows from one operation to the next: for this reason it is called **TensorFlow**\n",
    "\n",
    "<img src='data/tensor1.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* It's called **TensorFlow** because you're defining how data or tensors will *flow* through the system\n",
    "\n",
    "<img src='data/tensor2.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* TensorFlow is designed to be very generic and open-ended.\n",
    "* It can be used to model almost any series of calculations\n",
    "* It typically is used to build DNNs, but can be used to build almost any model\n",
    "\n",
    "#### Pros\n",
    "* Powerful and flexible\n",
    "* Can build almost anything\n",
    "\n",
    "#### Cons\n",
    "* High-learning cuve\n",
    "* Little done for you\n",
    "\n",
    "#### Hardware, software, and language requirements\n",
    "* TensorFlow has different hardware and software requirements for the development phase and the runtime phase\n",
    "    * **Development phase:**\n",
    "        * When you are coding and training an NN\n",
    "        * This is usually done on your own computer\n",
    "    * **Runtime (or inference) phase:**\n",
    "        * When you are making predictions with a trained NN\n",
    "        * This may be done on your own computer, on a cloud server, or on a user's computer or mobile device\n",
    "        \n",
    "#### Development phase requirements\n",
    "* Windows, macOS, or Linux\n",
    "* Can use multiple Linux computers (locally or in the cloud) for very large projects\n",
    "\n",
    "#### Runtime phase supports\n",
    "* Computers running Windows, macOS, or Linux\n",
    "* Linux servers running TensorFlow Serving\n",
    "* Google's Cloud Machine Learning Engine service\n",
    "* iOS or Android mobile apps\n",
    "\n",
    "\n",
    "* **The flexibility to run the same machine learning model on many different platforms is one of the best features of TensorFlow**\n",
    "\n",
    "#### GPU Acceleration\n",
    "* TensorFlow can take advantage of video cards with GPUs, like NVIDIA-brand GPUs (graphic processing units) to speed up training\n",
    "* GPUs are chips originally to speed up 3D video games but they are also good at the algebraic calculations needed to train neural networks\n",
    "* GPUs can greatly decrease NN training times for large neural networks\n",
    "* In fact, deep learning is only possible because GPUs let us train large neural networks in a reasonable amount of time \n",
    "* Keep in mind that TensorFlow **only supports NVIDIA-brand GPUs**.\n",
    "* We won't be using a GPU in this course, but keep in mind that having one is helpful when working on large projects.\n",
    "* **Note** that using a GPU with TensorFlow requires installing additional software from NVIDIA (**CUDA** and **cuDNN**) that aren't open source\n",
    "\n",
    "#### Programming Language Support\n",
    "* TensorFlow's core execution engine is written in C++ for speed\n",
    "* TensorFlow also lets other progamming languages control the C++ core\n",
    "* Python is the best supported and easiest language to use with TensorFlow\n",
    "* The main downside of using Python is that it is relatively slow to execute compared to a low-level language like the C or C++."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61767368",
   "metadata": {},
   "source": [
    "### The train/test/evaluation flow in TensorFlow\n",
    "\n",
    "#### Supervised Learning workflow:\n",
    "* Step 1: Choose a model\n",
    "* Step 2: Training phase\n",
    "* Step 3: Testing phase\n",
    "* Step 4: Evaluation phase\n",
    "\n",
    "#### TensorFlow workflow:\n",
    "* In TensorFlow, we'll follow these same steps\n",
    "* **However, you have to implement it yourself and set up a lot of the mechanics.**\n",
    "\n",
    "\n",
    "#### Step 1: Build a Model (as a Graph)\n",
    "* First define each layer of the NN and connect them together so that data flows from the first layer through to the last layer.\n",
    "* Then add the placeholder node that represents the data that will be fed in as input to the neural network\n",
    "* Add another placeholder node that represents the output, or values predicted by the neural network. \n",
    "* Next, we need a way to measure the accuracy of the neural network's predictions\n",
    "* We'll define the function that measures the accuracy of each prediction during the training process (this is the **loss function**).\n",
    "* The loss function gets added to the graph as its own operation \n",
    "* Then we have to create the **optimizer function** that tells TensorFlow how we want to train the model. When we run this function it will perform one training step on our model. We call this node the \"training operation\" in the chart below.\n",
    "* The training operation will train the neural network by looking at the results of the loss function and using that to adjust the weights of each layer in the neural network until they produce the desired output.\n",
    "* **Because this is a computational graph, there's no single start or end.** We can start processing at any node in the graph.\n",
    "* When you run an operation, TensorFlow will push any needed data through the network according to the pathways you defined to make everything work. \n",
    "* Once the ML algorithm is fully defined as a computational graph, we can move on to the training phase.\n",
    "\n",
    "<img src='data/tensor3.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "#### Step 2: Training Phase\n",
    "* **Before we can perform any operations, we have to create a TensorFlow *session*.**\n",
    "* A **session is an object in TensorFlow that runs operations on the graph and tracks the state of each node in the graph.**\n",
    "* Once the session object is created, we can ask it to run any operation in the graph.\n",
    "* To train the model, we'll call the training operation over and over.\n",
    "* Each time the training operation runs, we'll pass in new training data that will be used for that training pass\n",
    "* Then we'll check the current accuracy by call the loss function\n",
    "\n",
    "<img src='data/tensor4.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "#### TensorBoard\n",
    "* While the training process is running, we can watch the results graphically using a separate tool called **TensorBoard**. \n",
    "* TensorBoard is a web-based application that lets us visually monitor the system in real time.\n",
    "* We can use the graphs in TensorBoard to monitor how the accuracy is improving as the training process continues to run.\n",
    "\n",
    "<img src='data/tensor5.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "#### Step 3: Testing Phase\n",
    "* Now that the model is trained, we can move on to the testing phase.\n",
    "* We pass in testing data, and then measure the accuracy by calling the loss function.\n",
    "* The data will flow through the neural network and into the loss function, which will tell us how close the values predicted by the neural network were to the resl testing data.\n",
    "* Once we are happy with the accuracy of the predictions, we can save this model to a file \n",
    "* **When we save a trained model, we're actually writing out a copy of this graph, and a state of all nodes in the graph.**\n",
    "* When we load the model later, we're just restoring the graph to its previous state.\n",
    "\n",
    "<img src='data/tensor6.png' width=\"600\" height=\"300\" align=\"center\"/> \n",
    "\n",
    "#### Step 4: Evaluation phase\n",
    "* To use the model to make new predictions, we'll feed in data to the input node and call the output operation.\n",
    "* The data will flow through the neural network to the output node \n",
    "* The different nodes in the computational graph are used for different phases of the train/test evaluation flow.\n",
    "* In fact, when we are in the evaluation phase, and only using the graph to make new predictions, the loss function and the training operation are no longer needed at all \n",
    "* To make predictions, all we need are the nodes that make up the neural network itself. So when we deploy a trained neural network to the cloud or to a mobile device, we can strip out all the other parts of the computational graph and only include the parts we need to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9b43fd",
   "metadata": {},
   "source": [
    "### Build a simple model in TensorFlow\n",
    "* Let's start with a very simple TensorFlow computational graph that adds two numbers, $X$ and $Y$, together. \n",
    "* This graph has two inputs, $X$ and $Y$, as well as one operation, called $addition$.\n",
    "* Here's what the computational graph would look like:\n",
    "\n",
    "<img src='data/tensor7.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* **Note that it's standard practice to `import tensorflow as tf`**\n",
    "* By default, TF outputs a lot of log messages to your console when you run the program. The messages can sometimes be helpful, but can also make the output difficult to read.\n",
    "* When you create a node in TF, you have to choose what kind of node to create.\n",
    "* The $X$ and $Y$ nodes (from the graph above) will be placeholder nodes that get assigned a new value each time we make a calculation, so we create them as placeholder nodes.\n",
    "* Then we pass the $X$ and $Y$ nodes into the addition node.\n",
    "* **Recall that a TensorFlow session is an object that runs operations on the computation graph and tracks the state of each node in the graph.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d3c3a7",
   "metadata": {},
   "source": [
    "### Options for Loading Data\n",
    "* TF supports different ways of loading datasets, depending on how much data you are dealing with (the more data you have, the more complicated it gets):\n",
    "    * **Preload data into memory**\n",
    "        * Simplest method\n",
    "        * Pass data to TF as a single array\n",
    "        * Just write plain Python code to load data (nothing TF-specific)\n",
    "    * **Feed data step-by-step**\n",
    "        * Slightly more complicated version\n",
    "        * Feeds data step-by-step to TF as TF requests it\n",
    "        * Gives you more control over when the data is loaded\n",
    "        * Requires that you manage everything yourself\n",
    "    * **Set up a custom data pipeline**\n",
    "        * This is the best option when you are working with enormous datasets like millions of images\n",
    "        * Allows TF to manage loading data into memory itself as it needs it\n",
    "        \n",
    "#### Preload Data into Memory\n",
    "* Quick and easy\n",
    "* Works as long as the entire dataset fits into RAM\n",
    "* Use normal code with nothing TF-specific \n",
    "* Can use helpful Python data libraries like pandas\n",
    "\n",
    "#### Feed Data Step-by-Step\n",
    "* TF calles you custom data loader function each time it needs more data\n",
    "* This makes it possible to wor with larger datasets\n",
    "* But you have to write all the data loading code yourself\n",
    "* Normal Python code is used\n",
    "\n",
    "#### Set Up a Data Pipeline\n",
    "* Scales to infinitely large datasets\n",
    "* TF provides a good bit of plumbing for setting up a data pipeline, but you still have to write a good bit of code yourself\n",
    "* Requires writing TensorFlow-specific code (usually can't take advantage of other Python data processing libraries)\n",
    "* **Supports parallel processing** across multiple CPUs\n",
    "* This means that the training process doesn't have to stop and wait while the next chunk of data is loaded for the next training pass.\n",
    "\n",
    "#### Data Pipeline Example\n",
    "* Say our dataset is made up of hundreds of separate CSV files\n",
    "* First step: create a list of all the file names of the data files that need to be processed\n",
    "* Shuffle file names into a random order\n",
    "* Add the shuffled file names into a file processing queue\n",
    "* Next, individual file names will be pulled out of the file processing queue and sent to the CSV file reader\n",
    "* The CSV reader will parse the raw data out of the CSV file and break it up into individual records.\n",
    "* Each record in the CSV file is fed into the record decoder\n",
    "* The record decoder pulls out and formats the individual values from each record\n",
    "* Finally, queue up each record in the data queue, where it's ready to be fed into your neural network for training\n",
    "    * TF provides functions and helpers to help you build each step of this pipeline, and once you've built the pipeline, TF will execute it for you. \n",
    "    * Especially common for image-based datasets\n",
    "    \n",
    "#### Recommendations\n",
    "* Use the simplest solution (preloading) if possible\n",
    "* Build a data pipeline if your dataset becomes too large\n",
    "* Only add more complexity when you need it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10518bf",
   "metadata": {},
   "source": [
    "### Load the data set\n",
    "* We need to scale our data to be between 0 and 1\n",
    "* For this we can use the `MinMaxScaler()`\n",
    "    * pass in parameter `feature_range` and set to `=(0,1)`\n",
    "* First, create the scalers, then scale the training inputs and outputs:\n",
    "\n",
    "```\n",
    "X_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "Y_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "# Scale training inputs and outputs\n",
    "X_scaled_training = X_scaler.fit_transform(X_training)\n",
    "Y_scaled_training = Y_scaler.fit_transform(Y_training)\n",
    "\n",
    "# Scale testing inputs and outputs\n",
    "X_scaled_testing = X_scaler.transform(X_test)\n",
    "Y_scaled_testing =  Y_scaler.transform(Y_test)\n",
    "```\n",
    "* **Recall that the scaler transforms the data by multiplying the data by a constant value and then adding a constant value.**\n",
    "* We can get these values with:\n",
    "    * **`X_scaler.scale_[0]`**\n",
    "    * **`Y_scaler.scale_[0]`**\n",
    "* **This will be useful to know later, when we want to make predictions with the neural network and be able to unscale the data back to the original units.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e8fcf4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "258b620c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83ca042f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d316e768",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61f5e762",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cac9df14",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b6f7dca",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52c9952e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdfd1730",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "201e2c61",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fee3ff44",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "305cacb8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d915537e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b87b07f1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1de0e1f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e992a71c",
   "metadata": {},
   "source": [
    "<img src='data/tensor1.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
