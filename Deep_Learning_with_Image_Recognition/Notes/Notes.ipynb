{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ec6ea80",
   "metadata": {},
   "source": [
    "# Deep Learning: Image Recognition\n",
    "**Instructor:** Adam Geitgey\n",
    "\n",
    "Thanks to deep learning, image recognition systems have improved and are now used for everything from searching photo libraries to generating text-based descriptions of photographs. In this course, learn how to build a deep neural network that can recognize objects in photographs. Find out how to adjust state-of-the-art deep neural networks to recognize new objects, without the need to retrain the network. Explore cloud-based image recognition APIs that you can use as an alternative to building your own systems. Learn the steps involved to start building and deploying your own image recognition system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baff2e4e",
   "metadata": {},
   "source": [
    "#### Build cutting-edge image recognition systems\n",
    "* **Image recognition** is the ability for computers to look at a photograph and understand what's in the photograph\n",
    "* In the last few years, researchers have made major break throughs in image recognition thanks to neural networks\n",
    "* **Keras** is a high-level library for building neural networks in Python with only a few lines of code; built on top of either TensorFlow or Theano\n",
    "* One of the most important things to configure in a neural network is activation functions\n",
    "    * Before values flow from one layer to the next they pass through an activation function\n",
    "    * **Activation functions** decide which inputs from the previous layer are important enough to feed to the next layer\n",
    "* The final step of defining a neural network is to compile it by calling `model.compile()`; this tells Keras that we're done building the model and that we actually want to carry it out in memory\n",
    "* The optimizer algorithm is used to train the neural network\n",
    "* The loss function is how the training process measures how right or how wrong your NN's predictions are\n",
    "\n",
    "#### Using Images as Input to a NN\n",
    "* Bright points are closer to 255 and dark points are closer to 0\n",
    "* We can think of an image as a 3D array that is always three layers deep; so to be able to feed this image into a NN, we need the NN to have 1 input node for every number in this 3-D array (ie pixel)\n",
    "* These numbers add up very quickly\n",
    "* For a small **256 x 256 pixel image**, (by modern terms, a pretty tiny image):\n",
    "    * We need 256 x 256 x 3 = **196,608 input nodes**\n",
    "    * And that's just for the input layer\n",
    "    * The number of nodes in the entire neural network will quickly grow into the millions\n",
    "    * That's why using NNs for image processing in so computationally intensive\n",
    "        * **Because of this, image recognition systems tend to use small image sizes**\n",
    "        * It's very common to build image recognition systems that work with images that are **between 128 and 512 pixels wide.**\n",
    "        * Any larger than that, and it gets too slow and requires too much memory\n",
    "        * When working with larger images, we usually just scale them down to those smaller sizes before feeding them into the neural network "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645a8b74",
   "metadata": {},
   "source": [
    "### Recognizing Image Contents with a Neural Network\n",
    "* During the **inference phase** the neural network will give us a **prediction**; this prediction will be in the form of a probability\n",
    "* We can also build a single neural neetwork that has more than one output\n",
    "\n",
    "<img src='data/nn1.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* You can roughly think of the the top (leftmost) layers as looking for simple patterns like lines and sharp edges and the lower layers use the signals from the higher layers to look for more and more complex shapes and patterns\n",
    "* With all the layers working together, the model can identify very complex objects\n",
    "* That means that adding more layers to a NN tends to give it the capacity to learn more complex patterns and shapes; this is where the term **deep learning** originally came from\n",
    "* **Deep learning** is just the idea that making models deeper by adding more capacity to them lets us recognize more complex patterns in data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f9bcae",
   "metadata": {},
   "source": [
    "### Adding convolution for translational invariance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3b838d",
   "metadata": {},
   "source": [
    "* If we only train the NN with pictures of numbers that are perfectly centered, the NN will get confused if it sees anything else (for example, an uncentered \"8\")\n",
    "* For example:\n",
    "\n",
    "<img src='data/nn2.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "<img src='data/nn3.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6c88e5",
   "metadata": {},
   "source": [
    "* The neural network won't be able to make a good prediction on the uncentered 8 from the lower example above (where the model is only trained on centered 8s). \n",
    "* But, the 8 could appear anywhere in the image; it could just as easily appear at the bottom, like this:\n",
    "\n",
    "<img src='data/nn4.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c152ec7",
   "metadata": {},
   "source": [
    "* **We need to improve our neural network so that it can recognize objects in any position in the image.**\n",
    "    * This is called **Translation invariance.**\n",
    "    \n",
    "#### Translation Invariance and Convolutional Layers\n",
    "* **Translation invariance** is the idea that a machine learning model can recognize an object no matter whether it is moved (or *translated*) in the image.\n",
    "* The solution is to add a new type of layer to our neural network: a **convolutional layer**\n",
    "* Unlike a normal Dense layer, where every node is connected to every other node, this (convolutional) layer breaks apart the image in a special way so that it can recognize the same object in different positions\n",
    "* We do this by passing a small window (shown in orange below) over the image. \n",
    "* Each time it lands somewhere, we grab a new image tile; we repeat this until we've covered the entire image\n",
    "\n",
    "<img src='data/nn5.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* Next, we pass each image tile through the same NN layer(s). Each tile will be processed the same way and will save a value each time\n",
    "* In other words, we're turning the image into an array, where each entry in the array represents whether or not the neural network thinks a certain pattern appears at that part of the image\n",
    "* Next, we'll repeat the exact process again, but this time we'll use a different set of weights on the nodes in our NN layer\n",
    "* This will create another feature map that tells us whether or not a certain pattern appears in the image\n",
    "* But because we're using different weights, it will be looking for a different pattern than the first time\n",
    "* We can repeat this process several times until we have several layers in our new array \n",
    "\n",
    "<img src='data/nn6.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "<img src='data/nn7.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* This turns our original array into a 3D array\n",
    "* Each element in the array represents where (whether?) a certain pattern occurs\n",
    "* But because we are checking each tile of the original image, it doesn't matter where in the image a pattern occurs, we can find it anywhere\n",
    "* This **3D array is waht we'll feed into the next layer of the neural network.**\n",
    "* It will use this information to determine which patterns are most important in determining the final output\n",
    "* Adding a convolutional layer makes it possible for our neural network to be able to find the pattern, no matter where it appears in an image\n",
    "* **Normally, we'll have several convolutional layers** that repeat the above process multiple times. \n",
    "* **The rough idea is that we keep squishing down the image with each convolutional layer while still capturing the most important information from it.** By the time we reach the output layer, the neural network will have been able to identify whether or not the object appeared\n",
    "* Convolutional neural networks are the standard approach to building image recognition systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d563ca",
   "metadata": {},
   "source": [
    "## 3. Designing a Deep Neural Network for Image Recognition\n",
    "\n",
    "### Designing a neural network architecture for image recognition\n",
    "* Before we start coding our image recognition NN, let's sketch out how a basic neural network works\n",
    "* **A basic neural network comprised of all dense, or fully-connected, layers doesn't work efficiently for images because objects can appear in lots of different places in an image.**\n",
    "* The solution is to add one or more convolution layers, which help us detect patterns no matter where they appear in our image\n",
    "* **It can be very effective to place two or more convolutional layers in a row** so in our example we'll add them in pairs\n",
    "* The convolutional layers are looking for patterns in our image and recording whether or not they found those patterns in each part of our image; but we don't usually need to know *where* in an image a pattern was found down to the specific pixel; it's good enough to know the rough location where it was found. To solve this problem we can use a technique called **max pooling**\n",
    "\n",
    "#### Max Pooling\n",
    "\n",
    "<img src='data/nn8.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* We could pass the above information (regarding whether or not a pixel corresponds to a cloud) directly to the rest of our neural network, but it we can reduce the amount of information that we pass to the next layer, it will make the neural network's job much easier (and faster)\n",
    "* The idea of **max pooling** is to down sample the data by only passing on the most important bits\n",
    "\n",
    "<img src='data/nn9.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e79664",
   "metadata": {},
   "source": [
    "* The idea above is that, by capturing the most important data (most extreme values), we'll get nearly the same result, but much more efficiently.\n",
    "\n",
    "#### Dropout\n",
    "* **Dropout** is a technique to make the NN more robust and prevent overfitting\n",
    "* The idea is that we add a droppout layer between other layers that will randomly throw away some of the data passing throught by cutting some of the connections in the neural network\n",
    "\n",
    "<img src='data/nn10.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98ade66",
   "metadata": {},
   "source": [
    "* By randomly cutting connections with each training image, the neural network is forced to try harder to learn  multiple ways to represent the same ideas (rather than *memorize* an image).\n",
    "\n",
    "<img src='data/nn11.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* If we want to make our network more powerful and able to recognize more complex images, we can add more layers to it\n",
    "* But, instead of just adding layers randomly, we'll add more copies of our convolutional block.\n",
    "* When all these layers are working together, we'll be able to detect complex objects \n",
    "\n",
    "<img src='data/nn12.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* This is a very typical design for an image recognition neural network, but it's also one of the most basic\n",
    "* The latest designs involve branching pathways, shortcuts between groups of layers, and all sorts of other tricks, but they all build on these same basic ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0526af02",
   "metadata": {},
   "source": [
    "### Exploring the CIFAR-10 Data Set\n",
    "* [See here](https://www.cs.toronto.edu/~kriz/cifar.html) for more detail on the CIFAR-10 dataset (and AlexNet)\n",
    "\n",
    "#### Exploring your dataset\n",
    "   * Always look through the data by hand\n",
    "   * Check for obvious errors\n",
    "   * Verify that the data makes sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750300a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fb4346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905a5af3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95386a56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a3e675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682c89b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b63fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56731f3c",
   "metadata": {},
   "source": [
    "<img src='data/nn5.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
